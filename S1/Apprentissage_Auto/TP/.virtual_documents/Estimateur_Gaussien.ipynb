import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import  seaborn as sns





def calcul_moyenne(X):
    return np.array([np.array(X[X['y']==i][['x1','x2']].mean()) for i in range(1,6)])


def calcul_cov(X):
     return np.array([np.cov(np.array(X[X['y']==i][['x1','x2']]).T) for i in range(1,6)])


data1=pd.read_csv('data/data_tp1_app.txt',names=['y','x1','x2'],sep=" ")
test=pd.read_csv('data/data_tp1_dec.txt',names=['y','x1','x2'],sep=" ")
u=calcul_moyenne(data1)
cov=calcul_cov(data1)


def predi_distance_euclidien(x):
    dist=np.array([np.linalg.norm(x-u[i]) for i in range(5)])
    top1=np.argmin(dist)  
    dist[top1]=max(dist)+1 #je remplace la valeur de top1 par max+1 pour l'exclure
    top2=np.argmin(dist) #je recupere le nouveau top1(qui est en realite le top2)
    return top1+1,top2+1


def predi_distance_mahanalobis(x):
     dist=[(x-u[i]).T@np.linalg.inv(cov[i])@(x-u[i])+np.log(np.linalg.det(cov[i])) for i in range(5)]
     top1=np.argmin(dist)  
     dist[top1]=max(dist)+1 #je remplace la valeur de top1 par max+1 pour l'exclure
     top2=np.argmin(dist) #je recupere le nouveau top1(qui est en realite le top2)
     return top1+1,top2+1


def plot_decision_multi(x1_min, x1_max, x2_min, x2_max, prediction,sample = 300):
    x1_list = np.linspace(x1_min, x1_max, sample)
    x2_list = np.linspace(x2_min, x2_max, sample)
    y_grid_pred = [[prediction(np.array([x1,x2]))[0] for x1 in x1_list] for x2 in x2_list] 
    l = np.shape(np.unique(y_grid_pred))[0] - 1
    plt.contourf(x1_list, x2_list, y_grid_pred, levels=l, colors=plt.rcParams['axes.prop_cycle'].by_key()['color'], alpha=0.35)


def visualisation(test,methode):
    test=test[['x1','x2']]
    y_pred=[methode(i)[0] for i in test.values.tolist()]
    test['y_predi']=y_pred
    for label in range(1,6):
        plt.scatter(test[test['y_predi']== label]['x1'], test[test['y_predi']== label]['x2'], label=label)
    plt.legend()
    plot_decision_multi(test['x1'].min(),test['x1'].max(),test['x2'].min(),test['x2'].max(),prediction=methode)
    plt.axis('equal')
    plt.show()


visualisation(test,predi_distance_euclidien)


visualisation(test,predi_distance_mahanalobis)


def calcul_matrice(test,methode):
  y=list(test['y'])
  top1=[methode(k)[0] for k in test[['x1','x2']].values.tolist()]  
  top2=[methode(k)[1] for k in test[['x1','x2']].values.tolist()]  
  matrice=[[sum([1 if top1[k]==i and y[k]==j else 0 for k in range(len(y))]) for j in range(1,6)] for i in range(1,6)]
  errer_top1=sum([1 if top1[i]==y[i] else 0 for i in range(len(y))])/len(y)
  errer_top2=sum([1 if top2[i]==y[i] else 0 for i in range(len(y))])/len(y)
  return errer_top1,errer_top2,matrice


a,b,c=calcul_matrice(test,predi_distance_euclidien)
sns.heatmap(c)


a,b,c=calcul_matrice(test,predi_distance_mahanalobis)
sns.heatmap(c)


calcul_matrice(test,predi_distance_mahanalobis)





data2=pd.read_csv('data/data_tp2_app.txt',names=['y','x1','x2'],sep=" ")
test2=pd.read_csv('data/data_tp2_dec.txt',names=['y','x1','x2'],sep=" ")
u=calcul_moyenne(data2)
cov=calcul_cov(data2)


visualisation(test2,predi_distance_euclidien)


visualisation(test2,predi_distance_mahanalobis)


a,b,c=calcul_matrice(test2,predi_distance_euclidien)
sns.heatmap(c)


a,b,c=calcul_matrice(test2,predi_distance_mahanalobis)
sns.heatmap(c)





data3=pd.read_csv('data/data_tp3_app.txt',names=['y','x1','x2'],sep=" ")
test3=pd.read_csv('data/data_tp3_dec.txt',names=['y','x1','x2'],sep=" ")
u=calcul_moyenne(data3)
cov=calcul_cov(data3)


visualisation(test3,predi_distance_euclidien)


visualisation(test3,predi_distance_mahanalobis)


a,b,c=calcul_matrice(test3,predi_distance_mahanalobis)
sns.heatmap(c)


a,b,c=calcul_matrice(test2,predi_distance_euclidien)
sns.heatmap(c)





def plot_decision_multi2(x1_min, x1_max, x2_min, x2_max, prediction,data="",sample = 100):
    x1_list = np.linspace(x1_min, x1_max, sample)
    x2_list = np.linspace(x2_min, x2_max, sample)
    y_grid_pred = [[prediction(data,np.array([x1,x2]))[0] for x1 in x1_list] for x2 in x2_list] 
    l = np.shape(np.unique(y_grid_pred))[0] - 1
    plt.contourf(x1_list, x2_list, y_grid_pred, levels=l, colors=plt.rcParams['axes.prop_cycle'].by_key()['color'], alpha=0.35)


def visualisation2(test,methode,data=""):
    test=test[['x1','x2']]
    y_pred=[methode(data,i)[0] for i in test.values.tolist()]
    test['y_predi']=y_pred
    for label in range(1,7):
        plt.scatter(test[test['y_predi']== label]['x1'], test[test['y_predi']== label]['x2'], label=label)
    plt.legend()
    #plot_decision_multi2(test['x1'].min(),test['x1'].max(),test['x2'].min(),test['x2'].max(),prediction=methode,data=data)
    plt.axis('equal')
    plt.show()


def calcul_matrice2(tain,test,methode):
  y=list(test['y'])
  top1=[methode(tain,k)[0] for k in test[['x1','x2']].values.tolist()]  
  top2=[methode(tain,k)[1] for k in test[['x1','x2']].values.tolist()]  
  matrice=[[sum([1 if top1[k]==i and y[k]==j else 0 for k in range(len(y))]) for j in range(1,6)] for i in range(1,6)]
  errer_top1=sum([1 if top1[i]==y[i] else 0 for i in range(len(y))])/len(y)
  errer_top2=sum([1 if top2[i]==y[i] else 0 for i in range(len(y))])/len(y)
  return errer_top1,errer_top2,matrice


def parzen_uniforme(data,x):
   dist=[]
   for i in range(1,6):
       c=data[data['y']==i][['x1','x2']].values.tolist()
       dist.append(sum([0.5 if np.linalg.norm(np.array(j)-np.array(x))/1.5<1 else 0 for j in c]))
   if max(dist)==0:
       return 6,6
   top1=np.argmax(dist)  
   dist[top1]=min(dist)-1 #je remplace la valeur de top1 par min-1 pour l'exclure
   top2=np.argmax(dist) #je recupere le nouveau top1(qui est en realite le top2)
   return top1+1,top2+1


def parzen_gassien(data,x):
    s=1/((2*np.pi)**(len(x)/2))
    dist=np.array([sum([s*np.exp(-0.5*(np.array(j)-np.array(x)).T@ (np.array(j)-np.array(x))) for j in data[data['y']==i][['x1','x2']].values.tolist()])  for i in range(1,6)])
    top1=np.argmax(dist)  
    dist[top1]=min(dist)-1  #je remplace la valeur de top1 par min-1 pour l'exclure
    top2=np.argmax(dist) #je recupere le nouveau top1(qui est en realite le top2)
    return top1+1,top2+1


visualisation2(test,parzen_uniforme,data1)


for label in range(1,6):
    plt.scatter(data1[data1['y']== label]['x1'], data1[data1['y']== label]['x2'], label=label)


visualisation2(test,parzen_gassien,data1)


a,b,c=calcul_matrice(data1,test,parzen_uniforme)
sns.heatmap(c)


a,b,c=calcul_matrice(data1,test,parzen_gassien)
sns.heatmap(c)





def kppv(train,x,k=5):
    t=train.copy()
    t['dist']=[np.linalg.norm(np.array(y)-np.array(x)) for y in train[['x1','x2']].values.tolist()]
    k_voisins=list(t.sort_values('dist')[:k+1]['y'])
    majorite=max([k_voisins.count(i) for i in set(k_voisins)])
    classe=[i for i in set(k_voisins) if k_voisins.count(i)==majorite]
    return classe


visualisation2(test,kppv,data1)


a,b,c=calcul_matrice(traintest2,predi_distance_mahanalobis)
sns.heatmap(c)


for label in range(1,6):
    plt.scatter(data1[data1['y']== label]['x1'], data1[data1['y']== label]['x2'], label=label)
plt.legend()


dat=data1.copy()


dat[dat['y']==1]['y']=2
dat


dat[(dat['y']==1) | (dat['y']==2)]['y']


data1





def train_separatrice_lineaire(data):
    s=data[(data['y']==1) | (data['y']==2)]
    s=s[['x1','x2']]
    s['plus']=np.ones(len(s))
    s=np.array(s)
    a=np.ones(s.shape[1])
    for i in range(100):
        


train_separatrice_lineaire(data1)
