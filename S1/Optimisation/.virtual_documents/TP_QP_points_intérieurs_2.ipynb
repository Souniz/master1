



import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.svm import SVC



n_train = 100
X,y = make_moons(n_samples=100, shuffle=True, noise=None, random_state=None)
y = np.where(y> 0.5,y,-1)
for j in np.unique(y):
    plt.scatter(X[y==j,0],X[y==j,1],label=j)
plt.legend()




#%% SVM dual 
C =1000
N = X.shape[0]

from sklearn.metrics.pairwise import rbf_kernel
gamma = 1
N = X.shape[0]
K = rbf_kernel(X,gamma = gamma)
yb = y.reshape(N,1)
P = K*(yb@yb.T)
q = -np.ones(N)

clf = SVC(C=C,kernel='precomputed')
clf.fit(K, y)
indice_SV = clf.support_
alpha_sk = clf.dual_coef_[0]
b_sk = clf.intercept_

# construire le vecteur solution alpha_0

# %% 
alpha_o = np.zeros(N)
alpha_o[indice_SV] = np.abs(alpha_sk)
print('cout opt',0.5*alpha_o.T@P@alpha_o + q.T@alpha_o)

# calculer la valeur objective optimale du problème QP obtenu par ce solveur SVM
# et afficher le résultat








# Algorithme de point intérieur 

# construction du problème et des matrices associés

q = -np.ones(N)
b = np.array([0.0])
A = y.reshape(1,N)

# initialization du point intérieur

alpha = np.random.rand(N)*1e-2
nb_constraint = A.shape[0]

ll = np.ones((nb_constraint,1)) # multiplicateur de Lagrange
s = ((P@alpha   + q).reshape(N,1) - A.T@ ll).reshape(N)
s = np.where(s < 0.000001, 1e-16, s)  # on garde que les parties positives pour que s soit faisable

print('cout init',0.5*alpha.T@P@alpha + q.T@alpha)



x=alpha
sigma = 0.5
COUT=[]
for i in range(200):
    tau = x@s/N
    Sk = np.diag(s)
    Xk = np.diag(x)
    COUT.append(0.5*x.T@P@x + q.T@x)
    # construire les lignes de la Jacobienne
    # inserer votre code ici
    J1=np.hstack((P,-A.T,-np.eye(N)))
    J2=np.hstack((A,np.zeros((nb_constraint,nb_constraint)),np.zeros((nb_constraint,N))))
    J3=np.hstack((Sk,np.zeros((N,nb_constraint)),Xk))
    # construire la Jacobienne
    J = np.vstack((J1,J2,J3))  

    
    # construire les lignes du second membre(F(x))
    b1 = (P@x + q - s - (A.T@ll).flatten()).reshape(N,1)
    b2 = A@x-b
    b3 = (Xk@s-sigma*tau*np.ones(len(X))).reshape(N,1)
    
    second_membre = np.vstack((b1,b2,b3))
    
    # résoudre le problème
    J = J +1e-6*np.eye(2*N+nb_constraint)
    S = np.linalg.solve(J, -second_membre)
    
    # extraire les directions pour chaque partie
    dx =S[:N].flatten()
    dy = S[N:N+1].flatten()
    ds = S[N+1:].flatten() 
    
    # définir le pas optimal 
    step=1.
    while np.any(x+step*dx < 0) or np.any(s+step*ds < 0):
        step=0.5*step

    # mise à jour
    x = x + step*dx
    ll = ll + step*dy
    s = s + step*ds










