import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error
from sklearn.datasets import load_breast_cancer
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler





lambd1=np.random.normal((1,1),0.4,size=(300,2))
lambd2=np.random.normal((-1,-1),0.4,size=(300,2))


plt.scatter(lambd1[:,0],lambd1[:,1])
plt.scatter(lambd2[:,0],lambd2[:,1])






y=np.array([1 if i <300 else -1 for i in range(600)])
X=np.concatenate((lambd1,lambd2),axis=0)





clf=SVC(C=1000,kernel='linear',max_iter=-1)








clf.fit(X,y)
pass





clf.n_support_


indice_SV = clf.support_
alphas = clf.dual_coef_ [0]
b = clf.intercept_
print(f"Indices of support vectors: {indice_SV}, dual coefficients: {alphas},intercept: {b}")





len(alphas)








W=np.array(sum(alphas[i]*clf.support_vectors_[i] for i in range(len(alphas))))
W





clf.support_vectors_@W.T+b


def mesh(X, h=0.02):
    x_min , x_max = X[:, 0]. min() - .5, X[:, 0]. max() + .5
    y_min , y_max = X[:, 1]. min() - .5, X[:, 1]. max() + .5
    xx , yy = np.meshgrid(np.arange(x_min , x_max , h), np.arange(y_min , y_max , h))
    return np.c_[xx.ravel (), yy.ravel ()], xx , yy
xtest_grid , x_grid , y_grid = mesh(X)
Z = clf.predict(xtest_grid)
Z = Z.reshape(x_grid.shape)
# Plot decision and support boundaries:
plt.contour(x_grid , y_grid , Z, colors =['blue', 'black', 'darkorange'], levels =[-1,0, 1])
# Plot data points and support vectors:
plt.scatter(X[y == 1, 0], X[y == 1, 1], c='orange', s=20)
plt.scatter(X[y == -1, 0], X[y == -1, 1], c='b', s=20)
plt.scatter(clf.support_vectors_[:, 0],clf.support_vectors_[:, 1],s=100,linewidth=1,facecolors="none",edgecolors="k",label='points de support')
x1 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)
x2_marg_up = (1-W[0]*x1-b)/W[1] # le droite de support h(x)=W.Tx+b=1
x2_marg_down = (-1-W[0]*x1-b)/W[1] # le droite de support h(x)=W.Tx+b=-1
plt.plot(x1,x2_marg_up,label='Support UP',c='orange')
plt.plot(x1,x2_marg_down,label='Support down',c='blue')
plt.legend()
plt.show()





lambd1=np.random.normal((1,1),0.7,size=(300,2))
lambd2=np.random.normal((-1,-1),0.7,size=(300,2))
plt.scatter(lambd1[:,0],lambd1[:,1])
plt.scatter(lambd2[:,0],lambd2[:,1])


clf=SVC(C=1000,kernel='linear',max_iter=-1)
clf.fit(X,y)
pass


y=np.array([1 if i <300 else -1 for i in range(600)])
X=np.concatenate((lambd1,lambd2),axis=0)


def mesh(X, h=0.02):
    x_min , x_max = X[:, 0]. min() - .5, X[:, 0]. max() + .5
    y_min , y_max = X[:, 1]. min() - .5, X[:, 1]. max() + .5
    xx , yy = np.meshgrid(np.arange(x_min , x_max , h), np.arange(y_min , y_max , h))
    return np.c_[xx.ravel (), yy.ravel ()], xx , yy
xtest_grid , x_grid , y_grid = mesh(X)
Z = clf.predict(xtest_grid)
Z = Z.reshape(x_grid.shape)
# Plot decision and support boundaries:
plt.contour(x_grid , y_grid , Z, colors =['blue', 'black', 'darkorange'], levels =[-1,0, 1])
# Plot data points and support vectors:
plt.scatter(X[y == 1, 0], X[y == 1, 1], c='orange', s=20)
plt.scatter(X[y == -1, 0], X[y == -1, 1], c='b', s=20)
plt.scatter(clf.support_vectors_[:, 0],clf.support_vectors_[:, 1],s=100,linewidth=1,facecolors="none",edgecolors="k",label='points de support')
x1 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)
x2_marg_up = (1-W[0]*x1-b)/W[1] # le droite de support h(x)=W.Tx+b=1
x2_marg_down = (-1-W[0]*x1-b)/W[1] # le droite de support h(x)=W.Tx+b=-1
plt.plot(x1,x2_marg_up,label='Support UP',c='orange')
plt.plot(x1,x2_marg_down,label='Support down',c='blue')
plt.legend()
plt.show()
